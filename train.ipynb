{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fea8b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import numpy as np\n",
    "from network import ChessNetV2 as ChessNet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from replay_buffer import ReplayBuffer\n",
    "from state import move_to_index, move_mask\n",
    "import mcts\n",
    "import util\n",
    "import gc\n",
    "import time\n",
    "from device import device\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dc18d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(replay_buffer: ReplayBuffer, batch_size, net, optimizer):\n",
    "    net.train()\n",
    "    if replay_buffer.size() < batch_size:\n",
    "        return 0.0, 0.0, 0.0\n",
    "\n",
    "    boards, positions, target_policies, target_values = replay_buffer.sample(batch_size)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    pred_policies, pred_values = net(positions)\n",
    "\n",
    "    masks = torch.stack([torch.tensor(move_mask(board), dtype=torch.float32) for board in boards]).to(device)\n",
    "    masked_logits = pred_policies + (masks - 1) * 1e9\n",
    "    pred_probs = F.log_softmax(masked_logits, dim=1)\n",
    "\n",
    "    policy_loss = -torch.sum(target_policies * pred_probs, dim=1).mean()\n",
    "\n",
    "    value_loss = F.mse_loss(pred_values.squeeze(-1), target_values)\n",
    "    loss = policy_loss + value_loss\n",
    "\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(net.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item(), policy_loss.item(), value_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "357796e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_path = 'model.pth'\n",
    "optimizer_checkpoint_path = 'optimizer.pth'\n",
    "replay_buffer_checkpoint_path = 'replay-buffer.pkl'\n",
    "game_gif_path = 'game.gif'\n",
    "\n",
    "net = ChessNet(n_moves=len(move_to_index))\n",
    "try:\n",
    "    net.load_state_dict(torch.load(model_checkpoint_path), device=device)\n",
    "except: # checkpoint doesn't exist, continue with new model\n",
    "    pass\n",
    "net = net.to(device)\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=3e-4)\n",
    "try:\n",
    "    optimizer.load_state_dict(torch.load(optimizer_checkpoint_path))\n",
    "except: # checkpoint doesn't exist, continue with new optimizer\n",
    "    pass\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "n_epochs = 50\n",
    "n_selfplay_games = 12\n",
    "\n",
    "replay_buffer = ReplayBuffer(1000000)\n",
    "try:\n",
    "    replay_buffer.load(replay_buffer_checkpoint_path)\n",
    "except: # checkpoint doesn't exist, continue with new replay buffer\n",
    "    pass\n",
    "batch_size = 64\n",
    "\n",
    "n_sims = 800\n",
    "c_puct = 1.5\n",
    "temperature = 1.5\n",
    "temperature_threshold = 15\n",
    "alpha = 0.3\n",
    "epsilon = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cc8a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), model_checkpoint_path)\n",
    "torch.save(optimizer.state_dict(), optimizer_checkpoint_path)\n",
    "replay_buffer.save(replay_buffer_checkpoint_path)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_dir = os.path.join('games', f'epoch{epoch + 1}')\n",
    "    os.makedirs(epoch_dir, exist_ok=True)\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=12) as executor:\n",
    "        futures = [\n",
    "            executor.submit(\n",
    "                mcts.selfplay_wrapper, \n",
    "                model_checkpoint_path,\n",
    "                n_sims, \n",
    "                os.path.join(epoch_dir, f'game{i + 1}.txt'),\n",
    "                c_puct, \n",
    "                temperature,\n",
    "                temperature_threshold,\n",
    "                alpha, \n",
    "                epsilon,\n",
    "            ) for i in range(n_selfplay_games)\n",
    "        ]\n",
    "\n",
    "        for future in futures:\n",
    "            boards, positions, policies, values = future.result()\n",
    "            replay_buffer.add_game(boards, positions, policies, values)\n",
    "    \n",
    "    n_train_steps = 200\n",
    "    total_loss = 0\n",
    "    total_ploss = 0\n",
    "    total_vloss = 0\n",
    "    \n",
    "    for step in range(n_train_steps):\n",
    "        loss, ploss, vloss = train_step(replay_buffer, batch_size, net, optimizer)\n",
    "        total_loss += loss\n",
    "        total_ploss += ploss\n",
    "        total_vloss += vloss\n",
    "    \n",
    "    avg_loss = total_loss / n_train_steps\n",
    "    avg_ploss = total_ploss / n_train_steps\n",
    "    avg_vloss = total_vloss / n_train_steps\n",
    "\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    scheduler.step(avg_loss)\n",
    "    \n",
    "    print(f'Epoch {epoch + 1}: Loss: {avg_loss:.4f}, P_Loss: {avg_ploss:.4f}, V_loss: {avg_vloss:.4f}, Time: {(end - start):.2f}s')\n",
    "\n",
    "    torch.save(net.state_dict(), model_checkpoint_path)\n",
    "    torch.save(optimizer.state_dict(), optimizer_checkpoint_path)\n",
    "    replay_buffer.save(replay_buffer_checkpoint_path)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece94c8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
