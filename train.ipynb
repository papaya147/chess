{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fea8b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import numpy as np\n",
    "from network import ChessNetV2 as ChessNet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from replay_buffer import ReplayBuffer\n",
    "from state import move_to_index, move_mask\n",
    "import mcts\n",
    "import util\n",
    "import gc\n",
    "import time\n",
    "from device import device\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc18d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(replay_buffer: ReplayBuffer, batch_size, net, optimizer):\n",
    "    net.train()\n",
    "    if replay_buffer.size() < batch_size:\n",
    "        return 0.0, 0.0, 0.0\n",
    "\n",
    "    boards, positions, target_policies, target_values = replay_buffer.sample(batch_size)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    pred_policies, pred_values = net(positions)\n",
    "\n",
    "    masks = torch.stack([torch.tensor(move_mask(board), dtype=torch.float32) for board in boards]).to(device)\n",
    "    masked_logits = pred_policies + (masks - 1) * 1e9\n",
    "    pred_probs = F.log_softmax(masked_logits, dim=1)\n",
    "\n",
    "    policy_loss = -torch.sum(target_policies * pred_probs, dim=1).mean()\n",
    "\n",
    "    value_loss = F.mse_loss(pred_values.squeeze(-1), target_values)\n",
    "    loss = policy_loss + value_loss\n",
    "\n",
    "    loss.backward()\n",
    "    \n",
    "    grad_norm = torch.nn.utils.clip_grad_norm_(net.parameters(), 5.0)\n",
    "    \n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item(), policy_loss.item(), value_loss.item(), grad_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357796e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_path = 'model.pth'\n",
    "optimizer_checkpoint_path = 'optimizer.pth'\n",
    "replay_buffer_checkpoint_path = 'replay-buffer.pkl'\n",
    "game_gif_path = 'game.gif'\n",
    "\n",
    "net = ChessNet(n_moves=len(move_to_index))\n",
    "try:\n",
    "    net.load_state_dict(torch.load(model_checkpoint_path), device=device)\n",
    "except: # checkpoint doesn't exist, continue with new model\n",
    "    pass\n",
    "net = net.to(device)\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=5e-5, weight_decay=1e-5)\n",
    "try:\n",
    "    optimizer.load_state_dict(torch.load(optimizer_checkpoint_path))\n",
    "except: # checkpoint doesn't exist, continue with new optimizer\n",
    "    pass\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='min', \n",
    "    factor=0.7,\n",
    "    patience=3,\n",
    "    min_lr=1e-6,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "n_epochs = 50\n",
    "n_selfplay_games = 24\n",
    "n_train_steps = 1000\n",
    "\n",
    "replay_buffer = ReplayBuffer(500000, pct_recent=0.3, pct_recent_util=0.6)\n",
    "try:\n",
    "    replay_buffer.load(replay_buffer_checkpoint_path)\n",
    "except: # checkpoint doesn't exist, continue with new replay buffer\n",
    "    pass\n",
    "batch_size = 64\n",
    "\n",
    "n_sims = 800\n",
    "c_puct = 1.5\n",
    "temperature = 1.5\n",
    "temperature_threshold = 15\n",
    "alpha = 0.15\n",
    "epsilon = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cc8a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss: 2.3442, P_Loss: 2.1351, V_loss: 0.2091, LR: 0.000098, Time: 3347.58s\n",
      "Epoch 2: Loss: 2.1369, P_Loss: 1.8464, V_loss: 0.2905, LR: 0.000090, Time: 6583.69s\n",
      "Epoch 3: Loss: 2.0379, P_Loss: 1.7616, V_loss: 0.2764, LR: 0.000079, Time: 10202.22s\n",
      "Epoch 4: Loss: 2.2759, P_Loss: 1.9557, V_loss: 0.3203, LR: 0.000065, Time: 3236.83s\n",
      "Epoch 5: Loss: 1.8858, P_Loss: 1.7019, V_loss: 0.1839, LR: 0.000050, Time: 14491.06s\n",
      "Epoch 6: Loss: 2.0828, P_Loss: 1.7766, V_loss: 0.3063, LR: 0.000035, Time: 3014.15s\n",
      "Warning: Large gradient norm 10.26, skipping update\n",
      "Warning: Large gradient norm 10.06, skipping update\n",
      "Warning: Large gradient norm 10.24, skipping update\n",
      "Warning: Large gradient norm 10.15, skipping update\n",
      "Warning: Large gradient norm 10.14, skipping update\n",
      "Warning: Large gradient norm 10.12, skipping update\n",
      "Warning: Large gradient norm 10.17, skipping update\n",
      "Epoch 7: Loss: 2.1579, P_Loss: 1.8329, V_loss: 0.3250, LR: 0.000021, Time: 5375.12s\n",
      "Warning: Large gradient norm 11.03, skipping update\n",
      "Warning: Large gradient norm 10.83, skipping update\n",
      "Warning: Large gradient norm 10.25, skipping update\n",
      "Warning: Large gradient norm 10.15, skipping update\n",
      "Warning: Large gradient norm 10.87, skipping update\n",
      "Warning: Large gradient norm 10.10, skipping update\n",
      "Warning: Large gradient norm 10.81, skipping update\n",
      "Warning: Large gradient norm 10.33, skipping update\n",
      "Warning: Large gradient norm 10.28, skipping update\n",
      "Warning: Large gradient norm 10.05, skipping update\n",
      "Warning: Large gradient norm 10.14, skipping update\n",
      "Warning: Large gradient norm 10.52, skipping update\n",
      "Warning: Large gradient norm 10.06, skipping update\n",
      "Warning: Large gradient norm 10.09, skipping update\n",
      "Warning: Large gradient norm 10.01, skipping update\n",
      "Warning: Large gradient norm 10.02, skipping update\n",
      "Warning: Large gradient norm 10.20, skipping update\n",
      "Warning: Large gradient norm 11.07, skipping update\n",
      "Warning: Large gradient norm 10.11, skipping update\n",
      "Warning: Large gradient norm 10.58, skipping update\n",
      "Warning: Large gradient norm 10.19, skipping update\n",
      "Warning: Large gradient norm 10.86, skipping update\n",
      "Warning: Large gradient norm 10.08, skipping update\n",
      "Warning: Large gradient norm 10.16, skipping update\n",
      "Warning: Large gradient norm 10.84, skipping update\n",
      "Warning: Large gradient norm 10.49, skipping update\n",
      "Warning: Large gradient norm 10.19, skipping update\n",
      "Warning: Large gradient norm 11.24, skipping update\n",
      "Warning: Large gradient norm 10.01, skipping update\n",
      "Warning: Large gradient norm 11.18, skipping update\n",
      "Warning: Large gradient norm 11.01, skipping update\n",
      "Warning: Large gradient norm 10.27, skipping update\n",
      "Warning: Large gradient norm 10.04, skipping update\n",
      "Warning: Large gradient norm 10.02, skipping update\n",
      "Warning: Large gradient norm 10.02, skipping update\n",
      "Warning: Large gradient norm 10.03, skipping update\n",
      "Warning: Large gradient norm 10.00, skipping update\n",
      "Warning: Large gradient norm 10.91, skipping update\n",
      "Warning: Large gradient norm 10.54, skipping update\n",
      "Warning: Large gradient norm 10.08, skipping update\n",
      "Warning: Large gradient norm 10.82, skipping update\n",
      "Warning: Large gradient norm 10.03, skipping update\n",
      "Warning: Large gradient norm 10.65, skipping update\n",
      "Warning: Large gradient norm 10.20, skipping update\n",
      "Warning: Large gradient norm 11.30, skipping update\n",
      "Warning: Large gradient norm 11.34, skipping update\n",
      "Warning: Large gradient norm 10.80, skipping update\n",
      "Warning: Large gradient norm 10.11, skipping update\n",
      "Warning: Large gradient norm 10.69, skipping update\n",
      "Warning: Large gradient norm 10.32, skipping update\n",
      "Warning: Large gradient norm 11.27, skipping update\n",
      "Warning: Large gradient norm 10.05, skipping update\n",
      "Warning: Large gradient norm 10.18, skipping update\n",
      "Warning: Large gradient norm 10.77, skipping update\n",
      "Warning: Large gradient norm 10.02, skipping update\n",
      "Warning: Large gradient norm 10.29, skipping update\n",
      "Warning: Large gradient norm 10.05, skipping update\n",
      "Warning: Large gradient norm 10.02, skipping update\n",
      "Warning: Large gradient norm 10.95, skipping update\n",
      "Warning: Large gradient norm 10.08, skipping update\n",
      "Warning: Large gradient norm 10.13, skipping update\n",
      "Warning: Large gradient norm 10.86, skipping update\n",
      "Warning: Large gradient norm 10.46, skipping update\n",
      "Warning: Large gradient norm 11.83, skipping update\n",
      "Warning: Large gradient norm 10.55, skipping update\n",
      "Warning: Large gradient norm 10.40, skipping update\n",
      "Warning: Large gradient norm 10.22, skipping update\n",
      "Warning: Large gradient norm 10.29, skipping update\n",
      "Warning: Large gradient norm 10.12, skipping update\n",
      "Warning: Large gradient norm 10.27, skipping update\n",
      "Warning: Large gradient norm 10.15, skipping update\n",
      "Warning: Large gradient norm 10.26, skipping update\n",
      "Warning: Large gradient norm 10.90, skipping update\n",
      "Warning: Large gradient norm 10.39, skipping update\n",
      "Warning: Large gradient norm 11.17, skipping update\n",
      "Warning: Large gradient norm 10.67, skipping update\n",
      "Warning: Large gradient norm 10.52, skipping update\n",
      "Warning: Large gradient norm 10.14, skipping update\n",
      "Warning: Large gradient norm 10.00, skipping update\n",
      "Warning: Large gradient norm 10.07, skipping update\n",
      "Warning: Large gradient norm 10.90, skipping update\n",
      "Warning: Large gradient norm 10.67, skipping update\n",
      "Warning: Large gradient norm 10.72, skipping update\n",
      "Warning: Large gradient norm 10.13, skipping update\n",
      "Warning: Large gradient norm 10.10, skipping update\n",
      "Warning: Large gradient norm 10.48, skipping update\n",
      "Warning: Large gradient norm 10.15, skipping update\n",
      "Warning: Large gradient norm 10.40, skipping update\n",
      "Warning: Large gradient norm 10.50, skipping update\n",
      "Warning: Large gradient norm 10.20, skipping update\n",
      "Warning: Large gradient norm 10.04, skipping update\n",
      "Warning: Large gradient norm 10.04, skipping update\n",
      "Warning: Large gradient norm 10.24, skipping update\n",
      "Warning: Large gradient norm 10.40, skipping update\n",
      "Warning: Large gradient norm 10.08, skipping update\n",
      "Warning: Large gradient norm 10.18, skipping update\n",
      "Warning: Large gradient norm 10.07, skipping update\n",
      "Epoch 8: Loss: 1.6869, P_Loss: 1.4551, V_loss: 0.2318, LR: 0.000010, Time: 9684.61s\n",
      "Warning: Large gradient norm 12.25, skipping update\n",
      "Warning: Large gradient norm 11.03, skipping update\n",
      "Warning: Large gradient norm 10.06, skipping update\n",
      "Warning: Large gradient norm 11.55, skipping update\n",
      "Warning: Large gradient norm 10.78, skipping update\n",
      "Warning: Large gradient norm 10.44, skipping update\n",
      "Warning: Large gradient norm 11.55, skipping update\n",
      "Warning: Large gradient norm 10.73, skipping update\n",
      "Warning: Large gradient norm 10.88, skipping update\n",
      "Warning: Large gradient norm 10.99, skipping update\n",
      "Warning: Large gradient norm 11.36, skipping update\n",
      "Warning: Large gradient norm 11.34, skipping update\n",
      "Warning: Large gradient norm 11.21, skipping update\n",
      "Warning: Large gradient norm 10.56, skipping update\n",
      "Warning: Large gradient norm 11.00, skipping update\n",
      "Warning: Large gradient norm 10.86, skipping update\n",
      "Warning: Large gradient norm 11.62, skipping update\n",
      "Warning: Large gradient norm 11.76, skipping update\n",
      "Warning: Large gradient norm 11.45, skipping update\n",
      "Warning: Large gradient norm 11.82, skipping update\n",
      "Warning: Large gradient norm 11.31, skipping update\n",
      "Warning: Large gradient norm 11.32, skipping update\n",
      "Warning: Large gradient norm 10.75, skipping update\n",
      "Warning: Large gradient norm 10.33, skipping update\n",
      "Warning: Large gradient norm 11.62, skipping update\n",
      "Warning: Large gradient norm 10.36, skipping update\n",
      "Warning: Large gradient norm 10.68, skipping update\n",
      "Warning: Large gradient norm 11.05, skipping update\n",
      "Warning: Large gradient norm 11.32, skipping update\n",
      "Warning: Large gradient norm 10.18, skipping update\n",
      "Warning: Large gradient norm 10.86, skipping update\n",
      "Warning: Large gradient norm 10.54, skipping update\n",
      "Warning: Large gradient norm 10.03, skipping update\n",
      "Warning: Large gradient norm 10.85, skipping update\n",
      "Warning: Large gradient norm 11.72, skipping update\n",
      "Warning: Large gradient norm 10.45, skipping update\n",
      "Warning: Large gradient norm 10.36, skipping update\n",
      "Warning: Large gradient norm 10.25, skipping update\n",
      "Warning: Large gradient norm 11.24, skipping update\n",
      "Warning: Large gradient norm 11.42, skipping update\n",
      "Warning: Large gradient norm 10.03, skipping update\n",
      "Warning: Large gradient norm 10.73, skipping update\n",
      "Warning: Large gradient norm 11.82, skipping update\n",
      "Warning: Large gradient norm 11.53, skipping update\n",
      "Warning: Large gradient norm 11.71, skipping update\n",
      "Warning: Large gradient norm 10.90, skipping update\n",
      "Warning: Large gradient norm 11.35, skipping update\n",
      "Warning: Large gradient norm 11.89, skipping update\n",
      "Warning: Large gradient norm 10.89, skipping update\n",
      "Warning: Large gradient norm 11.12, skipping update\n",
      "Warning: Large gradient norm 10.65, skipping update\n",
      "Warning: Large gradient norm 11.06, skipping update\n",
      "Warning: Large gradient norm 11.26, skipping update\n",
      "Warning: Large gradient norm 10.93, skipping update\n",
      "Warning: Large gradient norm 10.22, skipping update\n",
      "Warning: Large gradient norm 10.23, skipping update\n",
      "Warning: Large gradient norm 11.06, skipping update\n",
      "Warning: Large gradient norm 10.61, skipping update\n",
      "Warning: Large gradient norm 10.16, skipping update\n",
      "Warning: Large gradient norm 10.45, skipping update\n",
      "Warning: Large gradient norm 11.59, skipping update\n",
      "Warning: Large gradient norm 10.98, skipping update\n",
      "Warning: Large gradient norm 10.31, skipping update\n",
      "Warning: Large gradient norm 10.47, skipping update\n",
      "Warning: Large gradient norm 11.52, skipping update\n",
      "Warning: Large gradient norm 10.66, skipping update\n",
      "Warning: Large gradient norm 10.64, skipping update\n",
      "Warning: Large gradient norm 10.19, skipping update\n",
      "Warning: Large gradient norm 11.95, skipping update\n",
      "Warning: Large gradient norm 10.81, skipping update\n",
      "Warning: Large gradient norm 11.24, skipping update\n",
      "Warning: Large gradient norm 11.63, skipping update\n",
      "Warning: Large gradient norm 10.19, skipping update\n",
      "Warning: Large gradient norm 11.39, skipping update\n",
      "Warning: Large gradient norm 11.64, skipping update\n",
      "Warning: Large gradient norm 10.35, skipping update\n",
      "Warning: Large gradient norm 10.24, skipping update\n",
      "Warning: Large gradient norm 10.56, skipping update\n",
      "Warning: Large gradient norm 10.67, skipping update\n",
      "Warning: Large gradient norm 10.96, skipping update\n",
      "Warning: Large gradient norm 10.27, skipping update\n",
      "Warning: Large gradient norm 11.69, skipping update\n",
      "Warning: Large gradient norm 11.00, skipping update\n",
      "Warning: Large gradient norm 12.10, skipping update\n",
      "Warning: Large gradient norm 11.19, skipping update\n",
      "Warning: Large gradient norm 10.60, skipping update\n",
      "Warning: Large gradient norm 11.36, skipping update\n",
      "Warning: Large gradient norm 10.99, skipping update\n",
      "Warning: Large gradient norm 11.94, skipping update\n",
      "Warning: Large gradient norm 10.62, skipping update\n",
      "Warning: Large gradient norm 10.35, skipping update\n",
      "Warning: Large gradient norm 11.41, skipping update\n",
      "Warning: Large gradient norm 10.70, skipping update\n",
      "Warning: Large gradient norm 12.10, skipping update\n",
      "Warning: Large gradient norm 10.70, skipping update\n",
      "Warning: Large gradient norm 11.04, skipping update\n",
      "Warning: Large gradient norm 10.63, skipping update\n",
      "Warning: Large gradient norm 10.07, skipping update\n",
      "Warning: Large gradient norm 12.74, skipping update\n",
      "Warning: Large gradient norm 10.03, skipping update\n",
      "Warning: Large gradient norm 11.35, skipping update\n",
      "Warning: Large gradient norm 10.82, skipping update\n",
      "Warning: Large gradient norm 10.97, skipping update\n",
      "Warning: Large gradient norm 11.04, skipping update\n",
      "Warning: Large gradient norm 13.08, skipping update\n",
      "Warning: Large gradient norm 11.96, skipping update\n",
      "Warning: Large gradient norm 10.82, skipping update\n",
      "Warning: Large gradient norm 11.85, skipping update\n",
      "Warning: Large gradient norm 11.31, skipping update\n",
      "Warning: Large gradient norm 11.75, skipping update\n",
      "Warning: Large gradient norm 10.97, skipping update\n",
      "Warning: Large gradient norm 10.89, skipping update\n",
      "Warning: Large gradient norm 10.76, skipping update\n",
      "Warning: Large gradient norm 11.06, skipping update\n",
      "Warning: Large gradient norm 11.18, skipping update\n",
      "Warning: Large gradient norm 11.98, skipping update\n",
      "Warning: Large gradient norm 13.06, skipping update\n",
      "Warning: Large gradient norm 11.06, skipping update\n",
      "Warning: Large gradient norm 10.60, skipping update\n",
      "Warning: Large gradient norm 10.50, skipping update\n",
      "Warning: Large gradient norm 10.18, skipping update\n",
      "Warning: Large gradient norm 10.94, skipping update\n",
      "Warning: Large gradient norm 11.13, skipping update\n",
      "Warning: Large gradient norm 12.29, skipping update\n",
      "Warning: Large gradient norm 11.33, skipping update\n",
      "Warning: Large gradient norm 11.88, skipping update\n",
      "Warning: Large gradient norm 10.12, skipping update\n",
      "Warning: Large gradient norm 11.22, skipping update\n",
      "Warning: Large gradient norm 11.48, skipping update\n",
      "Warning: Large gradient norm 10.39, skipping update\n",
      "Warning: Large gradient norm 11.87, skipping update\n",
      "Warning: Large gradient norm 11.06, skipping update\n",
      "Warning: Large gradient norm 10.07, skipping update\n",
      "Warning: Large gradient norm 10.11, skipping update\n",
      "Warning: Large gradient norm 11.61, skipping update\n",
      "Warning: Large gradient norm 10.61, skipping update\n",
      "Warning: Large gradient norm 11.26, skipping update\n",
      "Warning: Large gradient norm 11.49, skipping update\n",
      "Warning: Large gradient norm 10.65, skipping update\n",
      "Warning: Large gradient norm 10.73, skipping update\n",
      "Warning: Large gradient norm 11.75, skipping update\n",
      "Warning: Large gradient norm 10.90, skipping update\n",
      "Warning: Large gradient norm 12.26, skipping update\n",
      "Warning: Large gradient norm 11.26, skipping update\n",
      "Warning: Large gradient norm 11.34, skipping update\n",
      "Warning: Large gradient norm 11.12, skipping update\n",
      "Warning: Large gradient norm 10.08, skipping update\n",
      "Warning: Large gradient norm 11.38, skipping update\n",
      "Warning: Large gradient norm 11.29, skipping update\n",
      "Warning: Large gradient norm 10.02, skipping update\n",
      "Warning: Large gradient norm 10.02, skipping update\n",
      "Warning: Large gradient norm 10.57, skipping update\n",
      "Warning: Large gradient norm 10.47, skipping update\n",
      "Warning: Large gradient norm 10.46, skipping update\n",
      "Warning: Large gradient norm 10.50, skipping update\n",
      "Warning: Large gradient norm 10.10, skipping update\n",
      "Warning: Large gradient norm 10.65, skipping update\n",
      "Warning: Large gradient norm 11.78, skipping update\n",
      "Warning: Large gradient norm 11.32, skipping update\n",
      "Warning: Large gradient norm 11.74, skipping update\n",
      "Warning: Large gradient norm 10.30, skipping update\n",
      "Warning: Large gradient norm 10.52, skipping update\n",
      "Warning: Large gradient norm 10.61, skipping update\n",
      "Warning: Large gradient norm 10.43, skipping update\n",
      "Warning: Large gradient norm 10.18, skipping update\n",
      "Warning: Large gradient norm 10.29, skipping update\n",
      "Warning: Large gradient norm 10.00, skipping update\n",
      "Warning: Large gradient norm 10.75, skipping update\n",
      "Warning: Large gradient norm 11.55, skipping update\n",
      "Warning: Large gradient norm 10.69, skipping update\n",
      "Warning: Large gradient norm 10.90, skipping update\n",
      "Warning: Large gradient norm 10.40, skipping update\n",
      "Warning: Large gradient norm 10.04, skipping update\n",
      "Warning: Large gradient norm 11.61, skipping update\n",
      "Warning: Large gradient norm 10.81, skipping update\n",
      "Warning: Large gradient norm 11.02, skipping update\n",
      "Warning: Large gradient norm 10.79, skipping update\n",
      "Warning: Large gradient norm 11.24, skipping update\n",
      "Warning: Large gradient norm 10.44, skipping update\n",
      "Warning: Large gradient norm 10.25, skipping update\n",
      "Warning: Large gradient norm 10.62, skipping update\n",
      "Warning: Large gradient norm 10.89, skipping update\n",
      "Warning: Large gradient norm 10.96, skipping update\n",
      "Warning: Large gradient norm 10.38, skipping update\n",
      "Warning: Large gradient norm 10.37, skipping update\n",
      "Warning: Large gradient norm 11.88, skipping update\n",
      "Warning: Large gradient norm 10.34, skipping update\n",
      "Warning: Large gradient norm 12.01, skipping update\n",
      "Warning: Large gradient norm 10.22, skipping update\n",
      "Warning: Large gradient norm 10.49, skipping update\n",
      "Warning: Large gradient norm 10.53, skipping update\n",
      "Warning: Large gradient norm 10.21, skipping update\n",
      "Warning: Large gradient norm 11.38, skipping update\n",
      "Warning: Large gradient norm 10.24, skipping update\n",
      "Warning: Large gradient norm 11.28, skipping update\n",
      "Warning: Large gradient norm 11.86, skipping update\n",
      "Warning: Large gradient norm 10.44, skipping update\n",
      "Warning: Large gradient norm 11.32, skipping update\n",
      "Warning: Large gradient norm 11.40, skipping update\n",
      "Warning: Large gradient norm 11.05, skipping update\n",
      "Warning: Large gradient norm 11.71, skipping update\n",
      "Warning: Large gradient norm 11.71, skipping update\n",
      "Warning: Large gradient norm 11.47, skipping update\n",
      "Warning: Large gradient norm 11.38, skipping update\n",
      "Warning: Large gradient norm 12.19, skipping update\n",
      "Warning: Large gradient norm 12.41, skipping update\n",
      "Warning: Large gradient norm 11.83, skipping update\n",
      "Warning: Large gradient norm 10.69, skipping update\n",
      "Warning: Large gradient norm 10.62, skipping update\n",
      "Warning: Large gradient norm 11.46, skipping update\n",
      "Warning: Large gradient norm 10.29, skipping update\n",
      "Warning: Large gradient norm 11.20, skipping update\n",
      "Warning: Large gradient norm 10.24, skipping update\n",
      "Warning: Large gradient norm 10.32, skipping update\n",
      "Warning: Large gradient norm 10.41, skipping update\n",
      "Warning: Large gradient norm 12.34, skipping update\n",
      "Warning: Large gradient norm 10.29, skipping update\n",
      "Warning: Large gradient norm 10.95, skipping update\n",
      "Warning: Large gradient norm 11.74, skipping update\n",
      "Warning: Large gradient norm 10.36, skipping update\n",
      "Warning: Large gradient norm 10.14, skipping update\n",
      "Warning: Large gradient norm 11.62, skipping update\n",
      "Warning: Large gradient norm 10.28, skipping update\n",
      "Warning: Large gradient norm 12.13, skipping update\n",
      "Warning: Large gradient norm 10.96, skipping update\n",
      "Warning: Large gradient norm 10.02, skipping update\n",
      "Warning: Large gradient norm 10.60, skipping update\n",
      "Warning: Large gradient norm 10.70, skipping update\n",
      "Warning: Large gradient norm 11.64, skipping update\n",
      "Warning: Large gradient norm 10.84, skipping update\n",
      "Warning: Large gradient norm 10.56, skipping update\n",
      "Warning: Large gradient norm 10.31, skipping update\n",
      "Warning: Large gradient norm 10.94, skipping update\n",
      "Warning: Large gradient norm 10.60, skipping update\n",
      "Warning: Large gradient norm 11.01, skipping update\n",
      "Warning: Large gradient norm 10.43, skipping update\n",
      "Warning: Large gradient norm 10.26, skipping update\n",
      "Warning: Large gradient norm 10.21, skipping update\n",
      "Warning: Large gradient norm 10.16, skipping update\n",
      "Warning: Large gradient norm 10.93, skipping update\n",
      "Warning: Large gradient norm 12.05, skipping update\n",
      "Warning: Large gradient norm 10.31, skipping update\n",
      "Warning: Large gradient norm 10.18, skipping update\n",
      "Warning: Large gradient norm 10.71, skipping update\n",
      "Warning: Large gradient norm 10.10, skipping update\n",
      "Warning: Large gradient norm 11.71, skipping update\n",
      "Warning: Large gradient norm 10.14, skipping update\n",
      "Warning: Large gradient norm 10.22, skipping update\n",
      "Warning: Large gradient norm 10.74, skipping update\n",
      "Warning: Large gradient norm 11.48, skipping update\n",
      "Warning: Large gradient norm 12.26, skipping update\n",
      "Warning: Large gradient norm 10.91, skipping update\n",
      "Warning: Large gradient norm 10.73, skipping update\n",
      "Warning: Large gradient norm 10.91, skipping update\n",
      "Warning: Large gradient norm 10.45, skipping update\n",
      "Warning: Large gradient norm 10.14, skipping update\n",
      "Warning: Large gradient norm 10.89, skipping update\n",
      "Warning: Large gradient norm 10.48, skipping update\n",
      "Warning: Large gradient norm 10.96, skipping update\n",
      "Warning: Large gradient norm 10.87, skipping update\n",
      "Warning: Large gradient norm 10.84, skipping update\n",
      "Warning: Large gradient norm 10.65, skipping update\n",
      "Warning: Large gradient norm 12.04, skipping update\n",
      "Warning: Large gradient norm 10.81, skipping update\n",
      "Warning: Large gradient norm 12.31, skipping update\n",
      "Warning: Large gradient norm 10.77, skipping update\n",
      "Warning: Large gradient norm 11.57, skipping update\n",
      "Warning: Large gradient norm 10.47, skipping update\n",
      "Warning: Large gradient norm 10.44, skipping update\n",
      "Warning: Large gradient norm 10.39, skipping update\n",
      "Warning: Large gradient norm 10.91, skipping update\n",
      "Warning: Large gradient norm 11.51, skipping update\n",
      "Warning: Large gradient norm 10.94, skipping update\n",
      "Warning: Large gradient norm 10.42, skipping update\n",
      "Warning: Large gradient norm 10.85, skipping update\n",
      "Warning: Large gradient norm 12.53, skipping update\n",
      "Warning: Large gradient norm 11.30, skipping update\n",
      "Warning: Large gradient norm 11.62, skipping update\n",
      "Warning: Large gradient norm 10.16, skipping update\n",
      "Warning: Large gradient norm 10.61, skipping update\n",
      "Warning: Large gradient norm 11.07, skipping update\n",
      "Warning: Large gradient norm 12.86, skipping update\n",
      "Warning: Large gradient norm 10.69, skipping update\n",
      "Warning: Large gradient norm 11.71, skipping update\n",
      "Warning: Large gradient norm 11.25, skipping update\n",
      "Warning: Large gradient norm 10.19, skipping update\n",
      "Warning: Large gradient norm 11.02, skipping update\n",
      "Warning: Large gradient norm 11.75, skipping update\n",
      "Warning: Large gradient norm 11.26, skipping update\n",
      "Warning: Large gradient norm 10.50, skipping update\n",
      "Warning: Large gradient norm 10.84, skipping update\n",
      "Warning: Large gradient norm 10.88, skipping update\n",
      "Warning: Large gradient norm 12.70, skipping update\n",
      "Warning: Large gradient norm 13.02, skipping update\n",
      "Warning: Large gradient norm 10.54, skipping update\n",
      "Warning: Large gradient norm 11.13, skipping update\n",
      "Warning: Large gradient norm 10.60, skipping update\n",
      "Warning: Large gradient norm 10.64, skipping update\n",
      "Warning: Large gradient norm 10.30, skipping update\n",
      "Warning: Large gradient norm 10.44, skipping update\n",
      "Warning: Large gradient norm 10.90, skipping update\n",
      "Warning: Large gradient norm 10.11, skipping update\n",
      "Warning: Large gradient norm 10.86, skipping update\n",
      "Warning: Large gradient norm 11.47, skipping update\n",
      "Warning: Large gradient norm 11.43, skipping update\n",
      "Warning: Large gradient norm 11.33, skipping update\n",
      "Warning: Large gradient norm 10.59, skipping update\n",
      "Warning: Large gradient norm 10.08, skipping update\n",
      "Warning: Large gradient norm 12.87, skipping update\n",
      "Warning: Large gradient norm 11.04, skipping update\n",
      "Warning: Large gradient norm 10.03, skipping update\n",
      "Warning: Large gradient norm 10.47, skipping update\n",
      "Warning: Large gradient norm 10.97, skipping update\n",
      "Warning: Large gradient norm 10.49, skipping update\n",
      "Warning: Large gradient norm 10.74, skipping update\n",
      "Warning: Large gradient norm 10.55, skipping update\n",
      "Warning: Large gradient norm 10.54, skipping update\n",
      "Warning: Large gradient norm 10.08, skipping update\n",
      "Warning: Large gradient norm 11.19, skipping update\n",
      "Warning: Large gradient norm 11.14, skipping update\n",
      "Warning: Large gradient norm 10.92, skipping update\n",
      "Warning: Large gradient norm 10.54, skipping update\n",
      "Warning: Large gradient norm 10.77, skipping update\n",
      "Warning: Large gradient norm 10.88, skipping update\n",
      "Warning: Large gradient norm 11.09, skipping update\n",
      "Warning: Large gradient norm 11.35, skipping update\n",
      "Warning: Large gradient norm 11.12, skipping update\n",
      "Warning: Large gradient norm 11.20, skipping update\n",
      "Warning: Large gradient norm 11.55, skipping update\n",
      "Warning: Large gradient norm 12.33, skipping update\n",
      "Warning: Large gradient norm 13.27, skipping update\n",
      "Warning: Large gradient norm 12.13, skipping update\n",
      "Warning: Large gradient norm 10.68, skipping update\n",
      "Warning: Large gradient norm 10.65, skipping update\n",
      "Warning: Large gradient norm 10.65, skipping update\n",
      "Warning: Large gradient norm 10.07, skipping update\n",
      "Warning: Large gradient norm 10.59, skipping update\n",
      "Warning: Large gradient norm 11.49, skipping update\n",
      "Warning: Large gradient norm 10.13, skipping update\n",
      "Warning: Large gradient norm 12.03, skipping update\n",
      "Warning: Large gradient norm 11.92, skipping update\n",
      "Warning: Large gradient norm 10.64, skipping update\n",
      "Warning: Large gradient norm 12.92, skipping update\n",
      "Warning: Large gradient norm 10.73, skipping update\n",
      "Warning: Large gradient norm 11.19, skipping update\n",
      "Warning: Large gradient norm 11.29, skipping update\n",
      "Warning: Large gradient norm 10.19, skipping update\n",
      "Warning: Large gradient norm 11.28, skipping update\n",
      "Warning: Large gradient norm 10.47, skipping update\n",
      "Warning: Large gradient norm 11.72, skipping update\n",
      "Warning: Large gradient norm 10.77, skipping update\n",
      "Warning: Large gradient norm 11.49, skipping update\n",
      "Warning: Large gradient norm 10.35, skipping update\n",
      "Warning: Large gradient norm 10.87, skipping update\n",
      "Warning: Large gradient norm 12.78, skipping update\n",
      "Warning: Large gradient norm 10.83, skipping update\n",
      "Warning: Large gradient norm 11.03, skipping update\n",
      "Warning: Large gradient norm 10.77, skipping update\n",
      "Warning: Large gradient norm 12.69, skipping update\n",
      "Warning: Large gradient norm 10.13, skipping update\n",
      "Warning: Large gradient norm 12.86, skipping update\n",
      "Warning: Large gradient norm 10.02, skipping update\n",
      "Warning: Large gradient norm 11.28, skipping update\n",
      "Warning: Large gradient norm 12.18, skipping update\n",
      "Warning: Large gradient norm 11.06, skipping update\n",
      "Warning: Large gradient norm 10.99, skipping update\n",
      "Warning: Large gradient norm 11.26, skipping update\n",
      "Warning: Large gradient norm 11.26, skipping update\n",
      "Warning: Large gradient norm 10.76, skipping update\n",
      "Warning: Large gradient norm 10.10, skipping update\n",
      "Warning: Large gradient norm 10.29, skipping update\n",
      "Warning: Large gradient norm 10.31, skipping update\n",
      "Warning: Large gradient norm 11.13, skipping update\n",
      "Warning: Large gradient norm 10.77, skipping update\n",
      "Warning: Large gradient norm 10.28, skipping update\n",
      "Warning: Large gradient norm 11.31, skipping update\n",
      "Warning: Large gradient norm 10.96, skipping update\n",
      "Warning: Large gradient norm 11.59, skipping update\n",
      "Warning: Large gradient norm 11.30, skipping update\n",
      "Warning: Large gradient norm 10.15, skipping update\n",
      "Warning: Large gradient norm 10.67, skipping update\n",
      "Warning: Large gradient norm 10.67, skipping update\n",
      "Warning: Large gradient norm 11.43, skipping update\n",
      "Warning: Large gradient norm 10.65, skipping update\n",
      "Warning: Large gradient norm 11.53, skipping update\n",
      "Warning: Large gradient norm 11.00, skipping update\n",
      "Warning: Large gradient norm 11.08, skipping update\n",
      "Warning: Large gradient norm 11.44, skipping update\n",
      "Warning: Large gradient norm 12.02, skipping update\n",
      "Warning: Large gradient norm 10.68, skipping update\n",
      "Warning: Large gradient norm 10.69, skipping update\n",
      "Warning: Large gradient norm 10.70, skipping update\n",
      "Warning: Large gradient norm 11.14, skipping update\n",
      "Warning: Large gradient norm 10.36, skipping update\n",
      "Epoch 9: Loss: 0.4642, P_Loss: 0.3941, V_loss: 0.0701, LR: 0.000002, Time: 6145.02s\n",
      "Warning: Large gradient norm 12.26, skipping update\n",
      "Warning: Large gradient norm 12.38, skipping update\n",
      "Warning: Large gradient norm 11.68, skipping update\n",
      "Warning: Large gradient norm 12.11, skipping update\n",
      "Warning: Large gradient norm 11.10, skipping update\n",
      "Warning: Large gradient norm 10.65, skipping update\n",
      "Warning: Large gradient norm 11.36, skipping update\n",
      "Warning: Large gradient norm 12.30, skipping update\n",
      "Warning: Large gradient norm 12.00, skipping update\n",
      "Warning: Large gradient norm 11.08, skipping update\n",
      "Warning: Large gradient norm 11.53, skipping update\n",
      "Warning: Large gradient norm 11.90, skipping update\n",
      "Warning: Large gradient norm 10.29, skipping update\n",
      "Warning: Large gradient norm 11.68, skipping update\n",
      "Warning: Large gradient norm 10.52, skipping update\n",
      "Warning: Large gradient norm 11.76, skipping update\n",
      "Warning: Large gradient norm 12.47, skipping update\n",
      "Warning: Large gradient norm 12.31, skipping update\n",
      "Warning: Large gradient norm 10.41, skipping update\n",
      "Warning: Large gradient norm 10.70, skipping update\n",
      "Warning: Large gradient norm 10.75, skipping update\n",
      "Warning: Large gradient norm 11.32, skipping update\n",
      "Warning: Large gradient norm 12.15, skipping update\n",
      "Warning: Large gradient norm 10.70, skipping update\n",
      "Warning: Large gradient norm 10.11, skipping update\n",
      "Warning: Large gradient norm 10.13, skipping update\n",
      "Warning: Large gradient norm 11.82, skipping update\n",
      "Warning: Large gradient norm 11.23, skipping update\n",
      "Warning: Large gradient norm 11.64, skipping update\n",
      "Warning: Large gradient norm 10.76, skipping update\n",
      "Warning: Large gradient norm 12.63, skipping update\n",
      "Warning: Large gradient norm 11.09, skipping update\n",
      "Warning: Large gradient norm 12.26, skipping update\n",
      "Warning: Large gradient norm 10.98, skipping update\n",
      "Warning: Large gradient norm 11.48, skipping update\n",
      "Warning: Large gradient norm 11.79, skipping update\n",
      "Warning: Large gradient norm 10.95, skipping update\n",
      "Warning: Large gradient norm 11.60, skipping update\n",
      "Warning: Large gradient norm 10.15, skipping update\n",
      "Warning: Large gradient norm 12.25, skipping update\n",
      "Warning: Large gradient norm 11.55, skipping update\n",
      "Warning: Large gradient norm 12.35, skipping update\n",
      "Warning: Large gradient norm 11.74, skipping update\n",
      "Warning: Large gradient norm 11.14, skipping update\n",
      "Warning: Large gradient norm 10.62, skipping update\n",
      "Warning: Large gradient norm 12.81, skipping update\n",
      "Warning: Large gradient norm 11.74, skipping update\n",
      "Warning: Large gradient norm 11.28, skipping update\n",
      "Warning: Large gradient norm 13.02, skipping update\n",
      "Warning: Large gradient norm 11.41, skipping update\n",
      "Warning: Large gradient norm 11.15, skipping update\n",
      "Warning: Large gradient norm 11.25, skipping update\n",
      "Warning: Large gradient norm 11.19, skipping update\n",
      "Warning: Large gradient norm 11.40, skipping update\n",
      "Warning: Large gradient norm 11.94, skipping update\n",
      "Warning: Large gradient norm 10.64, skipping update\n",
      "Warning: Large gradient norm 12.02, skipping update\n",
      "Warning: Large gradient norm 12.00, skipping update\n",
      "Warning: Large gradient norm 11.63, skipping update\n",
      "Warning: Large gradient norm 11.01, skipping update\n",
      "Warning: Large gradient norm 10.93, skipping update\n",
      "Warning: Large gradient norm 10.51, skipping update\n",
      "Warning: Large gradient norm 10.13, skipping update\n",
      "Warning: Large gradient norm 11.77, skipping update\n",
      "Warning: Large gradient norm 10.20, skipping update\n",
      "Warning: Large gradient norm 12.01, skipping update\n",
      "Warning: Large gradient norm 12.16, skipping update\n",
      "Warning: Large gradient norm 11.78, skipping update\n",
      "Warning: Large gradient norm 11.99, skipping update\n",
      "Warning: Large gradient norm 12.40, skipping update\n",
      "Warning: Large gradient norm 10.91, skipping update\n",
      "Warning: Large gradient norm 11.06, skipping update\n",
      "Warning: Large gradient norm 10.31, skipping update\n",
      "Warning: Large gradient norm 11.10, skipping update\n",
      "Warning: Large gradient norm 11.37, skipping update\n",
      "Warning: Large gradient norm 10.52, skipping update\n",
      "Warning: Large gradient norm 11.71, skipping update\n",
      "Warning: Large gradient norm 10.57, skipping update\n",
      "Warning: Large gradient norm 11.09, skipping update\n",
      "Warning: Large gradient norm 12.15, skipping update\n",
      "Warning: Large gradient norm 10.56, skipping update\n",
      "Warning: Large gradient norm 11.39, skipping update\n",
      "Warning: Large gradient norm 10.58, skipping update\n",
      "Warning: Large gradient norm 11.39, skipping update\n",
      "Warning: Large gradient norm 11.85, skipping update\n",
      "Warning: Large gradient norm 10.92, skipping update\n",
      "Warning: Large gradient norm 11.71, skipping update\n",
      "Warning: Large gradient norm 11.20, skipping update\n",
      "Warning: Large gradient norm 10.11, skipping update\n",
      "Warning: Large gradient norm 11.47, skipping update\n",
      "Warning: Large gradient norm 10.06, skipping update\n",
      "Warning: Large gradient norm 11.41, skipping update\n",
      "Warning: Large gradient norm 10.83, skipping update\n",
      "Warning: Large gradient norm 10.59, skipping update\n",
      "Warning: Large gradient norm 11.41, skipping update\n",
      "Warning: Large gradient norm 11.17, skipping update\n",
      "Warning: Large gradient norm 11.98, skipping update\n",
      "Warning: Large gradient norm 11.41, skipping update\n",
      "Warning: Large gradient norm 10.89, skipping update\n",
      "Warning: Large gradient norm 11.17, skipping update\n",
      "Warning: Large gradient norm 11.17, skipping update\n",
      "Warning: Large gradient norm 11.93, skipping update\n",
      "Warning: Large gradient norm 11.15, skipping update\n",
      "Warning: Large gradient norm 10.42, skipping update\n",
      "Warning: Large gradient norm 12.07, skipping update\n",
      "Warning: Large gradient norm 11.02, skipping update\n",
      "Warning: Large gradient norm 12.27, skipping update\n",
      "Warning: Large gradient norm 11.22, skipping update\n",
      "Warning: Large gradient norm 11.83, skipping update\n",
      "Warning: Large gradient norm 12.67, skipping update\n",
      "Warning: Large gradient norm 11.04, skipping update\n",
      "Warning: Large gradient norm 10.89, skipping update\n",
      "Warning: Large gradient norm 11.03, skipping update\n",
      "Warning: Large gradient norm 10.55, skipping update\n",
      "Warning: Large gradient norm 11.23, skipping update\n",
      "Warning: Large gradient norm 11.18, skipping update\n",
      "Warning: Large gradient norm 10.51, skipping update\n",
      "Warning: Large gradient norm 12.07, skipping update\n",
      "Warning: Large gradient norm 12.64, skipping update\n",
      "Warning: Large gradient norm 11.38, skipping update\n",
      "Warning: Large gradient norm 11.48, skipping update\n",
      "Warning: Large gradient norm 13.19, skipping update\n",
      "Warning: Large gradient norm 11.19, skipping update\n",
      "Warning: Large gradient norm 11.66, skipping update\n",
      "Warning: Large gradient norm 11.56, skipping update\n",
      "Warning: Large gradient norm 11.25, skipping update\n",
      "Warning: Large gradient norm 12.07, skipping update\n",
      "Warning: Large gradient norm 12.74, skipping update\n",
      "Warning: Large gradient norm 12.78, skipping update\n",
      "Warning: Large gradient norm 10.19, skipping update\n",
      "Warning: Large gradient norm 13.43, skipping update\n",
      "Warning: Large gradient norm 10.63, skipping update\n",
      "Warning: Large gradient norm 11.86, skipping update\n",
      "Warning: Large gradient norm 10.44, skipping update\n",
      "Warning: Large gradient norm 13.45, skipping update\n",
      "Warning: Large gradient norm 13.00, skipping update\n",
      "Warning: Large gradient norm 12.44, skipping update\n",
      "Warning: Large gradient norm 10.17, skipping update\n",
      "Warning: Large gradient norm 11.62, skipping update\n",
      "Warning: Large gradient norm 11.76, skipping update\n",
      "Warning: Large gradient norm 12.32, skipping update\n",
      "Warning: Large gradient norm 10.57, skipping update\n",
      "Warning: Large gradient norm 13.24, skipping update\n",
      "Warning: Large gradient norm 12.10, skipping update\n",
      "Warning: Large gradient norm 10.44, skipping update\n",
      "Warning: Large gradient norm 11.43, skipping update\n",
      "Warning: Large gradient norm 11.00, skipping update\n",
      "Warning: Large gradient norm 11.07, skipping update\n",
      "Warning: Large gradient norm 11.00, skipping update\n",
      "Warning: Large gradient norm 12.60, skipping update\n",
      "Warning: Large gradient norm 10.85, skipping update\n",
      "Warning: Large gradient norm 11.11, skipping update\n",
      "Warning: Large gradient norm 10.55, skipping update\n",
      "Warning: Large gradient norm 11.42, skipping update\n",
      "Warning: Large gradient norm 11.88, skipping update\n",
      "Warning: Large gradient norm 10.78, skipping update\n",
      "Warning: Large gradient norm 12.06, skipping update\n",
      "Warning: Large gradient norm 12.79, skipping update\n",
      "Warning: Large gradient norm 12.01, skipping update\n",
      "Warning: Large gradient norm 12.59, skipping update\n",
      "Warning: Large gradient norm 10.65, skipping update\n",
      "Warning: Large gradient norm 11.08, skipping update\n",
      "Warning: Large gradient norm 11.30, skipping update\n",
      "Warning: Large gradient norm 10.50, skipping update\n",
      "Warning: Large gradient norm 10.89, skipping update\n",
      "Warning: Large gradient norm 11.82, skipping update\n",
      "Warning: Large gradient norm 11.89, skipping update\n",
      "Warning: Large gradient norm 11.47, skipping update\n",
      "Warning: Large gradient norm 11.15, skipping update\n",
      "Warning: Large gradient norm 11.17, skipping update\n",
      "Warning: Large gradient norm 10.66, skipping update\n",
      "Warning: Large gradient norm 11.70, skipping update\n",
      "Warning: Large gradient norm 11.35, skipping update\n",
      "Warning: Large gradient norm 11.32, skipping update\n",
      "Warning: Large gradient norm 12.53, skipping update\n",
      "Warning: Large gradient norm 12.69, skipping update\n",
      "Warning: Large gradient norm 10.63, skipping update\n",
      "Warning: Large gradient norm 10.90, skipping update\n",
      "Warning: Large gradient norm 10.50, skipping update\n",
      "Warning: Large gradient norm 11.28, skipping update\n",
      "Warning: Large gradient norm 12.14, skipping update\n",
      "Warning: Large gradient norm 11.92, skipping update\n",
      "Warning: Large gradient norm 11.29, skipping update\n",
      "Warning: Large gradient norm 10.69, skipping update\n",
      "Warning: Large gradient norm 12.07, skipping update\n",
      "Warning: Large gradient norm 11.31, skipping update\n",
      "Warning: Large gradient norm 10.84, skipping update\n",
      "Warning: Large gradient norm 12.61, skipping update\n",
      "Warning: Large gradient norm 12.27, skipping update\n",
      "Warning: Large gradient norm 10.71, skipping update\n",
      "Warning: Large gradient norm 11.65, skipping update\n",
      "Warning: Large gradient norm 10.54, skipping update\n",
      "Warning: Large gradient norm 11.07, skipping update\n",
      "Warning: Large gradient norm 12.26, skipping update\n",
      "Warning: Large gradient norm 10.47, skipping update\n",
      "Warning: Large gradient norm 12.03, skipping update\n",
      "Warning: Large gradient norm 11.54, skipping update\n",
      "Warning: Large gradient norm 11.24, skipping update\n",
      "Warning: Large gradient norm 11.92, skipping update\n",
      "Warning: Large gradient norm 12.65, skipping update\n",
      "Warning: Large gradient norm 12.29, skipping update\n",
      "Warning: Large gradient norm 11.59, skipping update\n",
      "Warning: Large gradient norm 11.55, skipping update\n",
      "Warning: Large gradient norm 10.26, skipping update\n",
      "Warning: Large gradient norm 12.22, skipping update\n",
      "Warning: Large gradient norm 10.18, skipping update\n",
      "Warning: Large gradient norm 10.42, skipping update\n",
      "Warning: Large gradient norm 11.72, skipping update\n",
      "Warning: Large gradient norm 12.45, skipping update\n",
      "Warning: Large gradient norm 13.03, skipping update\n",
      "Warning: Large gradient norm 11.16, skipping update\n",
      "Warning: Large gradient norm 11.00, skipping update\n",
      "Warning: Large gradient norm 11.78, skipping update\n",
      "Warning: Large gradient norm 10.35, skipping update\n",
      "Warning: Large gradient norm 10.79, skipping update\n",
      "Warning: Large gradient norm 12.03, skipping update\n",
      "Warning: Large gradient norm 11.04, skipping update\n",
      "Warning: Large gradient norm 13.47, skipping update\n",
      "Warning: Large gradient norm 11.64, skipping update\n",
      "Warning: Large gradient norm 11.69, skipping update\n",
      "Warning: Large gradient norm 10.21, skipping update\n",
      "Warning: Large gradient norm 11.94, skipping update\n",
      "Warning: Large gradient norm 10.64, skipping update\n",
      "Warning: Large gradient norm 11.53, skipping update\n",
      "Warning: Large gradient norm 10.96, skipping update\n",
      "Warning: Large gradient norm 10.90, skipping update\n",
      "Warning: Large gradient norm 11.49, skipping update\n",
      "Warning: Large gradient norm 11.77, skipping update\n",
      "Warning: Large gradient norm 10.17, skipping update\n",
      "Warning: Large gradient norm 11.18, skipping update\n",
      "Warning: Large gradient norm 11.35, skipping update\n",
      "Warning: Large gradient norm 10.30, skipping update\n",
      "Warning: Large gradient norm 10.80, skipping update\n",
      "Warning: Large gradient norm 11.25, skipping update\n",
      "Warning: Large gradient norm 11.56, skipping update\n",
      "Warning: Large gradient norm 11.21, skipping update\n",
      "Warning: Large gradient norm 11.62, skipping update\n",
      "Warning: Large gradient norm 13.10, skipping update\n",
      "Warning: Large gradient norm 11.67, skipping update\n",
      "Warning: Large gradient norm 11.64, skipping update\n",
      "Warning: Large gradient norm 11.63, skipping update\n",
      "Warning: Large gradient norm 12.99, skipping update\n",
      "Warning: Large gradient norm 11.90, skipping update\n",
      "Warning: Large gradient norm 10.70, skipping update\n",
      "Warning: Large gradient norm 13.07, skipping update\n",
      "Warning: Large gradient norm 11.82, skipping update\n",
      "Warning: Large gradient norm 10.34, skipping update\n",
      "Warning: Large gradient norm 11.17, skipping update\n",
      "Warning: Large gradient norm 12.25, skipping update\n",
      "Warning: Large gradient norm 10.28, skipping update\n",
      "Warning: Large gradient norm 12.26, skipping update\n",
      "Warning: Large gradient norm 12.17, skipping update\n",
      "Warning: Large gradient norm 12.23, skipping update\n",
      "Warning: Large gradient norm 13.17, skipping update\n",
      "Warning: Large gradient norm 11.94, skipping update\n",
      "Warning: Large gradient norm 11.17, skipping update\n",
      "Warning: Large gradient norm 10.09, skipping update\n",
      "Warning: Large gradient norm 11.77, skipping update\n",
      "Warning: Large gradient norm 11.93, skipping update\n",
      "Warning: Large gradient norm 10.15, skipping update\n",
      "Warning: Large gradient norm 12.77, skipping update\n",
      "Warning: Large gradient norm 11.26, skipping update\n",
      "Warning: Large gradient norm 11.98, skipping update\n",
      "Warning: Large gradient norm 11.18, skipping update\n",
      "Warning: Large gradient norm 10.90, skipping update\n",
      "Warning: Large gradient norm 12.00, skipping update\n",
      "Warning: Large gradient norm 10.94, skipping update\n",
      "Warning: Large gradient norm 10.63, skipping update\n",
      "Warning: Large gradient norm 11.93, skipping update\n",
      "Warning: Large gradient norm 10.35, skipping update\n",
      "Warning: Large gradient norm 11.43, skipping update\n",
      "Warning: Large gradient norm 12.44, skipping update\n",
      "Warning: Large gradient norm 12.36, skipping update\n",
      "Warning: Large gradient norm 10.74, skipping update\n",
      "Warning: Large gradient norm 11.31, skipping update\n",
      "Warning: Large gradient norm 11.07, skipping update\n",
      "Warning: Large gradient norm 12.49, skipping update\n",
      "Warning: Large gradient norm 12.13, skipping update\n",
      "Warning: Large gradient norm 10.64, skipping update\n",
      "Warning: Large gradient norm 10.15, skipping update\n",
      "Warning: Large gradient norm 10.86, skipping update\n",
      "Warning: Large gradient norm 12.66, skipping update\n",
      "Warning: Large gradient norm 11.92, skipping update\n",
      "Warning: Large gradient norm 10.48, skipping update\n",
      "Warning: Large gradient norm 10.49, skipping update\n",
      "Warning: Large gradient norm 10.80, skipping update\n",
      "Warning: Large gradient norm 11.12, skipping update\n",
      "Warning: Large gradient norm 11.21, skipping update\n",
      "Warning: Large gradient norm 10.97, skipping update\n",
      "Warning: Large gradient norm 11.93, skipping update\n",
      "Warning: Large gradient norm 10.12, skipping update\n",
      "Warning: Large gradient norm 11.21, skipping update\n",
      "Warning: Large gradient norm 11.87, skipping update\n",
      "Warning: Large gradient norm 12.52, skipping update\n",
      "Warning: Large gradient norm 12.22, skipping update\n",
      "Warning: Large gradient norm 10.91, skipping update\n",
      "Warning: Large gradient norm 10.70, skipping update\n",
      "Warning: Large gradient norm 11.90, skipping update\n",
      "Warning: Large gradient norm 11.21, skipping update\n",
      "Warning: Large gradient norm 11.69, skipping update\n",
      "Warning: Large gradient norm 12.38, skipping update\n",
      "Warning: Large gradient norm 12.01, skipping update\n",
      "Warning: Large gradient norm 11.14, skipping update\n",
      "Warning: Large gradient norm 11.13, skipping update\n",
      "Warning: Large gradient norm 12.66, skipping update\n",
      "Warning: Large gradient norm 11.56, skipping update\n",
      "Warning: Large gradient norm 12.07, skipping update\n",
      "Warning: Large gradient norm 11.10, skipping update\n",
      "Warning: Large gradient norm 12.60, skipping update\n",
      "Warning: Large gradient norm 11.27, skipping update\n",
      "Warning: Large gradient norm 11.86, skipping update\n",
      "Warning: Large gradient norm 11.12, skipping update\n",
      "Warning: Large gradient norm 10.60, skipping update\n",
      "Warning: Large gradient norm 11.19, skipping update\n",
      "Warning: Large gradient norm 11.96, skipping update\n",
      "Warning: Large gradient norm 11.11, skipping update\n",
      "Warning: Large gradient norm 10.06, skipping update\n",
      "Warning: Large gradient norm 11.37, skipping update\n",
      "Warning: Large gradient norm 12.17, skipping update\n",
      "Warning: Large gradient norm 10.71, skipping update\n",
      "Warning: Large gradient norm 11.19, skipping update\n",
      "Warning: Large gradient norm 12.53, skipping update\n",
      "Warning: Large gradient norm 10.82, skipping update\n",
      "Warning: Large gradient norm 10.99, skipping update\n",
      "Warning: Large gradient norm 10.71, skipping update\n",
      "Warning: Large gradient norm 11.51, skipping update\n",
      "Warning: Large gradient norm 12.86, skipping update\n",
      "Warning: Large gradient norm 11.25, skipping update\n",
      "Warning: Large gradient norm 12.19, skipping update\n",
      "Warning: Large gradient norm 12.18, skipping update\n",
      "Warning: Large gradient norm 11.00, skipping update\n",
      "Warning: Large gradient norm 11.09, skipping update\n",
      "Warning: Large gradient norm 12.18, skipping update\n",
      "Warning: Large gradient norm 11.26, skipping update\n",
      "Warning: Large gradient norm 12.24, skipping update\n",
      "Warning: Large gradient norm 11.76, skipping update\n",
      "Warning: Large gradient norm 12.27, skipping update\n",
      "Warning: Large gradient norm 11.17, skipping update\n",
      "Warning: Large gradient norm 10.72, skipping update\n",
      "Warning: Large gradient norm 12.26, skipping update\n",
      "Warning: Large gradient norm 11.97, skipping update\n",
      "Warning: Large gradient norm 11.64, skipping update\n",
      "Warning: Large gradient norm 11.33, skipping update\n",
      "Warning: Large gradient norm 13.42, skipping update\n",
      "Warning: Large gradient norm 12.13, skipping update\n",
      "Warning: Large gradient norm 11.32, skipping update\n",
      "Warning: Large gradient norm 10.37, skipping update\n",
      "Warning: Large gradient norm 11.07, skipping update\n",
      "Warning: Large gradient norm 13.16, skipping update\n",
      "Warning: Large gradient norm 11.75, skipping update\n",
      "Warning: Large gradient norm 11.56, skipping update\n",
      "Warning: Large gradient norm 11.57, skipping update\n",
      "Warning: Large gradient norm 10.33, skipping update\n",
      "Warning: Large gradient norm 11.14, skipping update\n",
      "Warning: Large gradient norm 10.49, skipping update\n",
      "Warning: Large gradient norm 12.06, skipping update\n",
      "Warning: Large gradient norm 11.68, skipping update\n",
      "Warning: Large gradient norm 10.64, skipping update\n",
      "Warning: Large gradient norm 11.73, skipping update\n",
      "Warning: Large gradient norm 11.68, skipping update\n",
      "Warning: Large gradient norm 12.77, skipping update\n",
      "Warning: Large gradient norm 11.56, skipping update\n",
      "Warning: Large gradient norm 11.32, skipping update\n",
      "Warning: Large gradient norm 12.06, skipping update\n",
      "Warning: Large gradient norm 10.05, skipping update\n",
      "Warning: Large gradient norm 11.25, skipping update\n",
      "Warning: Large gradient norm 11.86, skipping update\n",
      "Warning: Large gradient norm 10.89, skipping update\n",
      "Warning: Large gradient norm 12.38, skipping update\n",
      "Warning: Large gradient norm 11.09, skipping update\n",
      "Warning: Large gradient norm 10.67, skipping update\n",
      "Warning: Large gradient norm 12.92, skipping update\n",
      "Warning: Large gradient norm 11.88, skipping update\n",
      "Warning: Large gradient norm 10.31, skipping update\n",
      "Warning: Large gradient norm 10.56, skipping update\n",
      "Warning: Large gradient norm 11.30, skipping update\n",
      "Warning: Large gradient norm 11.04, skipping update\n",
      "Warning: Large gradient norm 12.66, skipping update\n",
      "Warning: Large gradient norm 11.10, skipping update\n",
      "Warning: Large gradient norm 10.14, skipping update\n",
      "Warning: Large gradient norm 11.06, skipping update\n",
      "Warning: Large gradient norm 12.00, skipping update\n",
      "Warning: Large gradient norm 10.60, skipping update\n",
      "Warning: Large gradient norm 10.55, skipping update\n",
      "Warning: Large gradient norm 10.37, skipping update\n",
      "Warning: Large gradient norm 11.41, skipping update\n",
      "Warning: Large gradient norm 10.71, skipping update\n",
      "Warning: Large gradient norm 10.54, skipping update\n",
      "Warning: Large gradient norm 12.16, skipping update\n",
      "Warning: Large gradient norm 10.83, skipping update\n",
      "Warning: Large gradient norm 11.05, skipping update\n",
      "Warning: Large gradient norm 11.85, skipping update\n",
      "Warning: Large gradient norm 11.58, skipping update\n",
      "Warning: Large gradient norm 11.72, skipping update\n",
      "Warning: Large gradient norm 11.36, skipping update\n",
      "Warning: Large gradient norm 11.62, skipping update\n",
      "Warning: Large gradient norm 10.14, skipping update\n",
      "Warning: Large gradient norm 10.47, skipping update\n",
      "Warning: Large gradient norm 10.08, skipping update\n",
      "Warning: Large gradient norm 12.28, skipping update\n",
      "Warning: Large gradient norm 12.07, skipping update\n",
      "Warning: Large gradient norm 12.87, skipping update\n",
      "Warning: Large gradient norm 10.21, skipping update\n",
      "Warning: Large gradient norm 11.53, skipping update\n",
      "Warning: Large gradient norm 10.69, skipping update\n",
      "Warning: Large gradient norm 11.07, skipping update\n",
      "Warning: Large gradient norm 11.21, skipping update\n",
      "Warning: Large gradient norm 11.13, skipping update\n",
      "Warning: Large gradient norm 11.50, skipping update\n",
      "Warning: Large gradient norm 11.75, skipping update\n",
      "Warning: Large gradient norm 11.88, skipping update\n",
      "Warning: Large gradient norm 10.43, skipping update\n",
      "Warning: Large gradient norm 10.99, skipping update\n",
      "Warning: Large gradient norm 11.26, skipping update\n",
      "Warning: Large gradient norm 11.22, skipping update\n",
      "Warning: Large gradient norm 12.20, skipping update\n",
      "Warning: Large gradient norm 11.05, skipping update\n",
      "Warning: Large gradient norm 11.69, skipping update\n",
      "Warning: Large gradient norm 10.99, skipping update\n",
      "Warning: Large gradient norm 11.34, skipping update\n",
      "Warning: Large gradient norm 12.01, skipping update\n",
      "Warning: Large gradient norm 10.51, skipping update\n",
      "Warning: Large gradient norm 10.58, skipping update\n",
      "Warning: Large gradient norm 10.32, skipping update\n",
      "Warning: Large gradient norm 12.05, skipping update\n",
      "Warning: Large gradient norm 10.62, skipping update\n",
      "Warning: Large gradient norm 12.06, skipping update\n",
      "Warning: Large gradient norm 10.94, skipping update\n",
      "Warning: Large gradient norm 11.76, skipping update\n",
      "Warning: Large gradient norm 10.28, skipping update\n",
      "Warning: Large gradient norm 10.67, skipping update\n",
      "Warning: Large gradient norm 11.74, skipping update\n",
      "Warning: Large gradient norm 11.75, skipping update\n",
      "Warning: Large gradient norm 11.62, skipping update\n",
      "Warning: Large gradient norm 13.22, skipping update\n",
      "Warning: Large gradient norm 10.92, skipping update\n",
      "Warning: Large gradient norm 10.92, skipping update\n",
      "Warning: Large gradient norm 11.31, skipping update\n",
      "Warning: Large gradient norm 12.31, skipping update\n",
      "Warning: Large gradient norm 12.42, skipping update\n",
      "Warning: Large gradient norm 12.71, skipping update\n",
      "Warning: Large gradient norm 12.16, skipping update\n",
      "Warning: Large gradient norm 10.60, skipping update\n",
      "Warning: Large gradient norm 11.20, skipping update\n",
      "Warning: Large gradient norm 11.32, skipping update\n",
      "Warning: Large gradient norm 12.48, skipping update\n",
      "Warning: Large gradient norm 10.44, skipping update\n",
      "Warning: Large gradient norm 10.15, skipping update\n",
      "Warning: Large gradient norm 11.07, skipping update\n",
      "Warning: Large gradient norm 11.37, skipping update\n",
      "Warning: Large gradient norm 11.21, skipping update\n",
      "Warning: Large gradient norm 11.44, skipping update\n",
      "Warning: Large gradient norm 11.60, skipping update\n",
      "Warning: Large gradient norm 10.89, skipping update\n",
      "Warning: Large gradient norm 12.32, skipping update\n",
      "Warning: Large gradient norm 10.95, skipping update\n",
      "Warning: Large gradient norm 10.51, skipping update\n",
      "Warning: Large gradient norm 11.11, skipping update\n",
      "Warning: Large gradient norm 11.64, skipping update\n",
      "Warning: Large gradient norm 10.58, skipping update\n",
      "Warning: Large gradient norm 11.72, skipping update\n",
      "Warning: Large gradient norm 11.70, skipping update\n",
      "Warning: Large gradient norm 11.79, skipping update\n",
      "Warning: Large gradient norm 10.51, skipping update\n",
      "Warning: Large gradient norm 10.62, skipping update\n",
      "Warning: Large gradient norm 10.97, skipping update\n",
      "Warning: Large gradient norm 10.78, skipping update\n",
      "Epoch 10: Loss: 0.1500, P_Loss: 0.1316, V_loss: 0.0185, LR: 0.000100, Time: 9601.48s\n",
      "Warning: Large gradient norm 12.38, skipping update\n",
      "Warning: Large gradient norm 11.39, skipping update\n",
      "Warning: Large gradient norm 11.13, skipping update\n",
      "Warning: Large gradient norm 10.52, skipping update\n",
      "Warning: Large gradient norm 12.39, skipping update\n",
      "Warning: Large gradient norm 11.18, skipping update\n",
      "Warning: Large gradient norm 12.94, skipping update\n",
      "Warning: Large gradient norm 11.93, skipping update\n",
      "Warning: Large gradient norm 12.91, skipping update\n",
      "Warning: Large gradient norm 10.43, skipping update\n",
      "Warning: Large gradient norm 11.37, skipping update\n",
      "Warning: Large gradient norm 11.49, skipping update\n",
      "Warning: Large gradient norm 10.76, skipping update\n",
      "Warning: Large gradient norm 12.43, skipping update\n",
      "Warning: Large gradient norm 10.55, skipping update\n",
      "Warning: Large gradient norm 12.24, skipping update\n",
      "Warning: Large gradient norm 11.79, skipping update\n",
      "Warning: Large gradient norm 12.16, skipping update\n",
      "Warning: Large gradient norm 10.91, skipping update\n",
      "Warning: Large gradient norm 10.24, skipping update\n",
      "Warning: Large gradient norm 11.24, skipping update\n",
      "Warning: Large gradient norm 12.19, skipping update\n",
      "Warning: Large gradient norm 11.53, skipping update\n",
      "Warning: Large gradient norm 10.80, skipping update\n",
      "Warning: Large gradient norm 10.76, skipping update\n",
      "Warning: Large gradient norm 12.86, skipping update\n",
      "Warning: Large gradient norm 11.94, skipping update\n",
      "Warning: Large gradient norm 10.66, skipping update\n",
      "Warning: Large gradient norm 12.23, skipping update\n",
      "Warning: Large gradient norm 12.16, skipping update\n",
      "Warning: Large gradient norm 13.06, skipping update\n",
      "Warning: Large gradient norm 11.56, skipping update\n",
      "Warning: Large gradient norm 10.40, skipping update\n",
      "Warning: Large gradient norm 12.98, skipping update\n",
      "Warning: Large gradient norm 10.84, skipping update\n",
      "Warning: Large gradient norm 12.07, skipping update\n",
      "Warning: Large gradient norm 10.47, skipping update\n",
      "Warning: Large gradient norm 10.27, skipping update\n",
      "Warning: Large gradient norm 10.69, skipping update\n",
      "Warning: Large gradient norm 11.73, skipping update\n",
      "Warning: Large gradient norm 11.99, skipping update\n",
      "Warning: Large gradient norm 11.87, skipping update\n",
      "Warning: Large gradient norm 11.10, skipping update\n",
      "Warning: Large gradient norm 13.07, skipping update\n",
      "Warning: Large gradient norm 10.62, skipping update\n",
      "Warning: Large gradient norm 11.21, skipping update\n",
      "Warning: Large gradient norm 12.84, skipping update\n",
      "Warning: Large gradient norm 12.56, skipping update\n",
      "Warning: Large gradient norm 11.28, skipping update\n",
      "Warning: Large gradient norm 11.53, skipping update\n",
      "Warning: Large gradient norm 12.08, skipping update\n",
      "Warning: Large gradient norm 10.30, skipping update\n",
      "Warning: Large gradient norm 10.10, skipping update\n",
      "Warning: Large gradient norm 11.70, skipping update\n",
      "Warning: Large gradient norm 10.97, skipping update\n",
      "Warning: Large gradient norm 11.56, skipping update\n",
      "Warning: Large gradient norm 11.36, skipping update\n",
      "Warning: Large gradient norm 10.94, skipping update\n",
      "Warning: Large gradient norm 11.24, skipping update\n",
      "Warning: Large gradient norm 10.11, skipping update\n",
      "Warning: Large gradient norm 10.07, skipping update\n",
      "Warning: Large gradient norm 10.18, skipping update\n",
      "Warning: Large gradient norm 11.52, skipping update\n",
      "Warning: Large gradient norm 11.04, skipping update\n",
      "Warning: Large gradient norm 11.90, skipping update\n",
      "Warning: Large gradient norm 10.51, skipping update\n",
      "Warning: Large gradient norm 10.06, skipping update\n",
      "Warning: Large gradient norm 10.89, skipping update\n",
      "Warning: Large gradient norm 11.37, skipping update\n",
      "Warning: Large gradient norm 10.52, skipping update\n",
      "Warning: Large gradient norm 10.59, skipping update\n",
      "Warning: Large gradient norm 10.95, skipping update\n",
      "Warning: Large gradient norm 11.19, skipping update\n",
      "Warning: Large gradient norm 10.64, skipping update\n",
      "Warning: Large gradient norm 11.34, skipping update\n",
      "Warning: Large gradient norm 11.19, skipping update\n",
      "Warning: Large gradient norm 10.94, skipping update\n",
      "Warning: Large gradient norm 11.35, skipping update\n",
      "Warning: Large gradient norm 10.64, skipping update\n",
      "Warning: Large gradient norm 11.67, skipping update\n",
      "Warning: Large gradient norm 11.19, skipping update\n",
      "Warning: Large gradient norm 11.35, skipping update\n",
      "Warning: Large gradient norm 10.75, skipping update\n",
      "Warning: Large gradient norm 10.54, skipping update\n",
      "Warning: Large gradient norm 11.79, skipping update\n",
      "Warning: Large gradient norm 12.10, skipping update\n",
      "Warning: Large gradient norm 10.14, skipping update\n",
      "Warning: Large gradient norm 10.17, skipping update\n",
      "Warning: Large gradient norm 13.49, skipping update\n",
      "Warning: Large gradient norm 11.29, skipping update\n",
      "Warning: Large gradient norm 12.02, skipping update\n",
      "Warning: Large gradient norm 12.04, skipping update\n",
      "Warning: Large gradient norm 10.35, skipping update\n",
      "Warning: Large gradient norm 10.35, skipping update\n",
      "Warning: Large gradient norm 10.94, skipping update\n",
      "Warning: Large gradient norm 12.40, skipping update\n",
      "Warning: Large gradient norm 11.37, skipping update\n",
      "Warning: Large gradient norm 11.44, skipping update\n",
      "Warning: Large gradient norm 11.65, skipping update\n",
      "Warning: Large gradient norm 12.00, skipping update\n",
      "Warning: Large gradient norm 10.11, skipping update\n",
      "Warning: Large gradient norm 11.65, skipping update\n",
      "Warning: Large gradient norm 11.00, skipping update\n",
      "Warning: Large gradient norm 11.17, skipping update\n",
      "Warning: Large gradient norm 10.18, skipping update\n",
      "Warning: Large gradient norm 10.93, skipping update\n",
      "Warning: Large gradient norm 11.45, skipping update\n",
      "Warning: Large gradient norm 12.12, skipping update\n",
      "Warning: Large gradient norm 11.14, skipping update\n",
      "Warning: Large gradient norm 10.69, skipping update\n",
      "Warning: Large gradient norm 12.72, skipping update\n",
      "Warning: Large gradient norm 11.71, skipping update\n",
      "Warning: Large gradient norm 13.09, skipping update\n",
      "Warning: Large gradient norm 12.69, skipping update\n",
      "Warning: Large gradient norm 11.75, skipping update\n",
      "Warning: Large gradient norm 10.61, skipping update\n",
      "Warning: Large gradient norm 11.20, skipping update\n",
      "Warning: Large gradient norm 10.06, skipping update\n",
      "Warning: Large gradient norm 10.33, skipping update\n",
      "Warning: Large gradient norm 10.83, skipping update\n",
      "Warning: Large gradient norm 10.72, skipping update\n",
      "Warning: Large gradient norm 10.79, skipping update\n",
      "Warning: Large gradient norm 11.00, skipping update\n",
      "Warning: Large gradient norm 10.60, skipping update\n",
      "Warning: Large gradient norm 11.57, skipping update\n",
      "Warning: Large gradient norm 10.39, skipping update\n",
      "Warning: Large gradient norm 11.77, skipping update\n",
      "Warning: Large gradient norm 10.44, skipping update\n",
      "Warning: Large gradient norm 11.22, skipping update\n",
      "Warning: Large gradient norm 10.96, skipping update\n",
      "Warning: Large gradient norm 11.49, skipping update\n",
      "Warning: Large gradient norm 10.04, skipping update\n",
      "Warning: Large gradient norm 10.72, skipping update\n",
      "Warning: Large gradient norm 10.53, skipping update\n",
      "Warning: Large gradient norm 11.26, skipping update\n",
      "Warning: Large gradient norm 10.59, skipping update\n",
      "Warning: Large gradient norm 10.60, skipping update\n",
      "Warning: Large gradient norm 10.38, skipping update\n",
      "Warning: Large gradient norm 11.68, skipping update\n",
      "Warning: Large gradient norm 10.94, skipping update\n",
      "Warning: Large gradient norm 11.69, skipping update\n",
      "Warning: Large gradient norm 11.02, skipping update\n",
      "Warning: Large gradient norm 10.26, skipping update\n",
      "Warning: Large gradient norm 12.08, skipping update\n",
      "Warning: Large gradient norm 10.43, skipping update\n",
      "Warning: Large gradient norm 10.02, skipping update\n",
      "Warning: Large gradient norm 11.50, skipping update\n",
      "Warning: Large gradient norm 10.96, skipping update\n",
      "Warning: Large gradient norm 10.89, skipping update\n",
      "Warning: Large gradient norm 11.25, skipping update\n",
      "Warning: Large gradient norm 11.82, skipping update\n",
      "Warning: Large gradient norm 10.88, skipping update\n",
      "Warning: Large gradient norm 11.15, skipping update\n",
      "Warning: Large gradient norm 10.17, skipping update\n",
      "Warning: Large gradient norm 11.14, skipping update\n",
      "Warning: Large gradient norm 10.02, skipping update\n",
      "Warning: Large gradient norm 10.38, skipping update\n",
      "Warning: Large gradient norm 11.45, skipping update\n",
      "Warning: Large gradient norm 10.81, skipping update\n",
      "Warning: Large gradient norm 10.14, skipping update\n",
      "Warning: Large gradient norm 10.17, skipping update\n",
      "Warning: Large gradient norm 10.37, skipping update\n",
      "Warning: Large gradient norm 11.00, skipping update\n",
      "Warning: Large gradient norm 10.42, skipping update\n",
      "Warning: Large gradient norm 10.80, skipping update\n",
      "Warning: Large gradient norm 10.76, skipping update\n",
      "Warning: Large gradient norm 10.18, skipping update\n",
      "Warning: Large gradient norm 10.76, skipping update\n",
      "Warning: Large gradient norm 10.66, skipping update\n",
      "Warning: Large gradient norm 10.22, skipping update\n",
      "Warning: Large gradient norm 10.12, skipping update\n",
      "Warning: Large gradient norm 11.28, skipping update\n",
      "Warning: Large gradient norm 11.19, skipping update\n",
      "Warning: Large gradient norm 10.64, skipping update\n",
      "Warning: Large gradient norm 10.04, skipping update\n",
      "Warning: Large gradient norm 10.42, skipping update\n",
      "Warning: Large gradient norm 10.03, skipping update\n",
      "Warning: Large gradient norm 10.26, skipping update\n",
      "Warning: Large gradient norm 10.77, skipping update\n",
      "Warning: Large gradient norm 11.03, skipping update\n",
      "Warning: Large gradient norm 10.02, skipping update\n",
      "Warning: Large gradient norm 11.00, skipping update\n",
      "Warning: Large gradient norm 10.50, skipping update\n",
      "Warning: Large gradient norm 10.71, skipping update\n",
      "Warning: Large gradient norm 10.37, skipping update\n",
      "Warning: Large gradient norm 10.26, skipping update\n",
      "Warning: Large gradient norm 11.87, skipping update\n",
      "Warning: Large gradient norm 10.42, skipping update\n",
      "Warning: Large gradient norm 11.52, skipping update\n",
      "Warning: Large gradient norm 11.30, skipping update\n",
      "Warning: Large gradient norm 10.41, skipping update\n",
      "Warning: Large gradient norm 10.35, skipping update\n",
      "Warning: Large gradient norm 10.65, skipping update\n",
      "Warning: Large gradient norm 10.07, skipping update\n",
      "Warning: Large gradient norm 11.40, skipping update\n",
      "Warning: Large gradient norm 10.51, skipping update\n",
      "Warning: Large gradient norm 10.45, skipping update\n",
      "Warning: Large gradient norm 10.17, skipping update\n",
      "Warning: Large gradient norm 10.27, skipping update\n",
      "Warning: Large gradient norm 10.47, skipping update\n",
      "Warning: Large gradient norm 10.47, skipping update\n",
      "Warning: Large gradient norm 10.59, skipping update\n",
      "Warning: Large gradient norm 10.46, skipping update\n",
      "Warning: Large gradient norm 11.62, skipping update\n",
      "Warning: Large gradient norm 11.60, skipping update\n",
      "Warning: Large gradient norm 10.12, skipping update\n",
      "Warning: Large gradient norm 11.19, skipping update\n",
      "Warning: Large gradient norm 10.21, skipping update\n",
      "Warning: Large gradient norm 10.52, skipping update\n",
      "Warning: Large gradient norm 10.16, skipping update\n",
      "Warning: Large gradient norm 10.49, skipping update\n",
      "Warning: Large gradient norm 10.56, skipping update\n",
      "Warning: Large gradient norm 10.67, skipping update\n",
      "Warning: Large gradient norm 10.85, skipping update\n",
      "Warning: Large gradient norm 10.33, skipping update\n",
      "Warning: Large gradient norm 10.24, skipping update\n",
      "Warning: Large gradient norm 10.33, skipping update\n",
      "Warning: Large gradient norm 10.01, skipping update\n",
      "Warning: Large gradient norm 10.01, skipping update\n",
      "Warning: Large gradient norm 10.01, skipping update\n",
      "Warning: Large gradient norm 10.59, skipping update\n",
      "Warning: Large gradient norm 10.57, skipping update\n",
      "Warning: Large gradient norm 10.30, skipping update\n",
      "Warning: Large gradient norm 10.22, skipping update\n",
      "Warning: Large gradient norm 10.09, skipping update\n",
      "Warning: Large gradient norm 11.13, skipping update\n",
      "Warning: Large gradient norm 10.03, skipping update\n",
      "Warning: Large gradient norm 10.05, skipping update\n",
      "Warning: Large gradient norm 10.22, skipping update\n",
      "Warning: Large gradient norm 10.03, skipping update\n",
      "Epoch 11: Loss: 1.2538, P_Loss: 1.0888, V_loss: 0.1650, LR: 0.000099, Time: 6465.84s\n",
      "Epoch 12: Loss: 2.1998, P_Loss: 1.9318, V_loss: 0.2680, LR: 0.000098, Time: 2673.52s\n",
      "Epoch 13: Loss: 2.2998, P_Loss: 1.9646, V_loss: 0.3352, LR: 0.000095, Time: 4773.95s\n",
      "Epoch 14: Loss: 2.2997, P_Loss: 1.9767, V_loss: 0.3230, LR: 0.000090, Time: 2484.56s\n",
      "Epoch 15: Loss: 2.3109, P_Loss: 1.9804, V_loss: 0.3304, LR: 0.000085, Time: 1909.42s\n",
      "Epoch 16: Loss: 2.2945, P_Loss: 1.9619, V_loss: 0.3326, LR: 0.000079, Time: 2203.34s\n",
      "Epoch 17: Loss: 2.3021, P_Loss: 1.9834, V_loss: 0.3186, LR: 0.000073, Time: 2104.52s\n",
      "Epoch 18: Loss: 2.3471, P_Loss: 2.0222, V_loss: 0.3250, LR: 0.000065, Time: 1068.73s\n",
      "Epoch 19: Loss: 2.3614, P_Loss: 2.0336, V_loss: 0.3278, LR: 0.000058, Time: 4451.10s\n",
      "Epoch 20: Loss: 2.3751, P_Loss: 2.0393, V_loss: 0.3358, LR: 0.000050, Time: 2114.88s\n",
      "Epoch 21: Loss: 2.3139, P_Loss: 2.0194, V_loss: 0.2945, LR: 0.000042, Time: 2164.91s\n",
      "Epoch 22: Loss: 2.2842, P_Loss: 2.0084, V_loss: 0.2759, LR: 0.000035, Time: 1936.80s\n",
      "Epoch 23: Loss: 2.2469, P_Loss: 1.9606, V_loss: 0.2863, LR: 0.000027, Time: 8811.53s\n",
      "Warning: Large gradient norm 10.00, skipping update\n",
      "Epoch 24: Loss: 2.1671, P_Loss: 1.9025, V_loss: 0.2646, LR: 0.000021, Time: 2663.58s\n",
      "Epoch 25: Loss: 2.1347, P_Loss: 1.8780, V_loss: 0.2567, LR: 0.000015, Time: 10041.43s\n",
      "Epoch 26: Loss: 2.1173, P_Loss: 1.8645, V_loss: 0.2528, LR: 0.000010, Time: 1403.54s\n",
      "Warning: Large gradient norm 10.41, skipping update\n",
      "Epoch 27: Loss: 2.1740, P_Loss: 1.8779, V_loss: 0.2961, LR: 0.000005, Time: 8037.94s\n",
      "Warning: Large gradient norm 10.58, skipping update\n",
      "Warning: Large gradient norm 10.86, skipping update\n",
      "Epoch 28: Loss: 2.1803, P_Loss: 1.8798, V_loss: 0.3005, LR: 0.000002, Time: 4026.18s\n",
      "Warning: Large gradient norm 10.10, skipping update\n",
      "Warning: Large gradient norm 10.11, skipping update\n",
      "Warning: Large gradient norm 10.32, skipping update\n",
      "Warning: Large gradient norm 10.07, skipping update\n",
      "Warning: Large gradient norm 10.28, skipping update\n",
      "Epoch 29: Loss: 2.1769, P_Loss: 1.8883, V_loss: 0.2885, LR: 0.000001, Time: 1753.04s\n",
      "Warning: Large gradient norm 10.53, skipping update\n",
      "Warning: Large gradient norm 10.45, skipping update\n",
      "Warning: Large gradient norm 10.58, skipping update\n",
      "Warning: Large gradient norm 10.57, skipping update\n",
      "Warning: Large gradient norm 10.42, skipping update\n",
      "Warning: Large gradient norm 10.29, skipping update\n",
      "Warning: Large gradient norm 10.22, skipping update\n",
      "Epoch 30: Loss: 2.2380, P_Loss: 1.9554, V_loss: 0.2827, LR: 0.000100, Time: 2697.82s\n",
      "Warning: Large gradient norm 10.30, skipping update\n",
      "Warning: Large gradient norm 11.05, skipping update\n",
      "Warning: Large gradient norm 10.49, skipping update\n",
      "Epoch 31: Loss: 2.3340, P_Loss: 2.0219, V_loss: 0.3121, LR: 0.000100, Time: 1454.64s\n",
      "Epoch 32: Loss: 2.3293, P_Loss: 1.9998, V_loss: 0.3294, LR: 0.000099, Time: 1390.93s\n",
      "Epoch 33: Loss: 2.3331, P_Loss: 2.0082, V_loss: 0.3249, LR: 0.000099, Time: 1302.94s\n",
      "Epoch 34: Loss: 2.3388, P_Loss: 2.0210, V_loss: 0.3178, LR: 0.000098, Time: 805.73s\n",
      "Epoch 35: Loss: 2.3224, P_Loss: 2.0063, V_loss: 0.3161, LR: 0.000096, Time: 1020.98s\n",
      "Epoch 36: Loss: 2.3623, P_Loss: 2.0437, V_loss: 0.3186, LR: 0.000095, Time: 1724.67s\n",
      "Epoch 37: Loss: 2.3168, P_Loss: 2.0136, V_loss: 0.3032, LR: 0.000093, Time: 1351.10s\n",
      "Epoch 38: Loss: 2.3653, P_Loss: 2.0593, V_loss: 0.3060, LR: 0.000090, Time: 1250.68s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnProcess-462:\n",
      "Process SpawnProcess-461:\n",
      "Process SpawnProcess-457:\n",
      "Process SpawnProcess-459:\n",
      "Process SpawnProcess-467:\n",
      "Process SpawnProcess-464:\n",
      "Process SpawnProcess-463:\n",
      "Process SpawnProcess-465:\n",
      "Process SpawnProcess-458:\n",
      "Process SpawnProcess-468:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/concurrent/futures/process.py\", line 249, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/concurrent/futures/process.py\", line 249, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/concurrent/futures/process.py\", line 249, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/concurrent/futures/process.py\", line 249, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/concurrent/futures/process.py\", line 249, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/concurrent/futures/process.py\", line 249, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/concurrent/futures/process.py\", line 249, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/concurrent/futures/process.py\", line 249, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/concurrent/futures/process.py\", line 249, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/concurrent/futures/process.py\", line 249, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/multiprocessing/queues.py\", line 103, in get\n",
      "    res = self._recv_bytes()\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/multiprocessing/connection.py\", line 430, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/Users/abhinavsrivatsa/projects/chess-bot/env/lib/python3.11/multiprocessing/connection.py\", line 395, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     12\u001b[39m     futures = [\n\u001b[32m     13\u001b[39m         executor.submit(\n\u001b[32m     14\u001b[39m             mcts.selfplay_wrapper, \n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m         ) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_selfplay_games)\n\u001b[32m     24\u001b[39m     ]\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m futures:\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m         boards, positions, policies, values = \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m         replay_buffer.add_game(boards, positions, policies, values)\n\u001b[32m     30\u001b[39m n_train_steps = \u001b[32m500\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/chess-bot/env/lib/python3.11/concurrent/futures/_base.py:451\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m    449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__get_result()\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_condition\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/chess-bot/env/lib/python3.11/threading.py:327\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    329\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "torch.save(net.state_dict(), model_checkpoint_path)\n",
    "torch.save(optimizer.state_dict(), optimizer_checkpoint_path)\n",
    "replay_buffer.save(replay_buffer_checkpoint_path)\n",
    "\n",
    "best_loss = float('inf')\n",
    "patience_counter = 0\n",
    "max_patience = 15\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_dir = os.path.join('games', f'epoch{epoch + 1}')\n",
    "    os.makedirs(epoch_dir, exist_ok=True)\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    print(f\"\\nEpoch {epoch + 1}: Starting selfplay...\")\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=12) as executor:\n",
    "        futures = [\n",
    "            executor.submit(\n",
    "                mcts.selfplay_wrapper, \n",
    "                model_checkpoint_path,\n",
    "                n_sims, \n",
    "                os.path.join(epoch_dir, f'game{i + 1}.txt'),\n",
    "                c_puct, \n",
    "                temperature,\n",
    "                temperature_threshold,\n",
    "                alpha, \n",
    "                epsilon,\n",
    "            ) for i in range(n_selfplay_games)\n",
    "        ]\n",
    "\n",
    "        positions_added = 0\n",
    "        game_results = {'1-0': 0, '0-1': 0, '1/2-1/2': 0}\n",
    "\n",
    "        for future in futures:\n",
    "            boards, positions, policies, values = future.result()\n",
    "            replay_buffer.add_game(boards, positions, policies, values)\n",
    "            positions_added += len(positions)\n",
    "\n",
    "            result = boards[-1].result()\n",
    "            if result in game_results:\n",
    "                game_results[result] += 1\n",
    "            \n",
    "    print(f\"Added {positions_added} positions. Buffer: {replay_buffer.size()}\")\n",
    "    print(f\"Win Results - White: {game_results.get('1-0', 0)}, \"\n",
    "          f\"Black: {game_results.get('0-1', 0)}, \"\n",
    "          f\"Draw: {game_results.get('1/2-1/2', 0)}\")\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_ploss = 0\n",
    "    total_vloss = 0\n",
    "    total_grad_norm = 0\n",
    "    \n",
    "    for step in range(n_train_steps):\n",
    "        loss, ploss, vloss, grad_norm = train_step(replay_buffer, batch_size, net, optimizer)\n",
    "        total_loss += loss\n",
    "        total_ploss += ploss\n",
    "        total_vloss += vloss\n",
    "        total_grad_norm += grad_norm\n",
    "\n",
    "    \n",
    "    avg_loss = total_loss / n_train_steps\n",
    "    avg_ploss = total_ploss / n_train_steps\n",
    "    avg_vloss = total_vloss / n_train_steps\n",
    "    avg_grad_norm = total_grad_norm / n_train_steps\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    old_lr = optimizer.param_groups[0]['lr']\n",
    "    scheduler.step()\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    print(f'\\nEpoch {epoch + 1}: Loss: {avg_loss:.4f}, P_Loss: {avg_ploss:.4f}, '\n",
    "          f'V_loss: {avg_vloss:.4f}, Avg_GradNorm: {avg_grad_norm:.2f}, '\n",
    "          f'LR: {current_lr:.6f}, Time: {(end - start)/60:.2f}m')\n",
    "    \n",
    "    if avg_loss < best_loss - 0.01:\n",
    "        best_loss = avg_loss\n",
    "        patience_counter = 0\n",
    "        print(f\"New best loss! Saving checkpoint...\")\n",
    "        torch.save(net.state_dict(), model_checkpoint_path)\n",
    "        torch.save(optimizer.state_dict(), optimizer_checkpoint_path)\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"No improvement. Patience: {patience_counter}/{max_patience}\")\n",
    "        if patience_counter >= max_patience:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break\n",
    "    \n",
    "    replay_buffer.save(replay_buffer_checkpoint_path)\n",
    "\n",
    "    if current_lr != old_lr:\n",
    "        print(f\"Learning rate reduced: {old_lr:.6f} -> {current_lr:.6f}\")\n",
    "\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece94c8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
